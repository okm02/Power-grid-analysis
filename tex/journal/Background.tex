\section{Background}
\label{background}

\subsection{Resilience analysis using Graph Theory}
\label{resilience}

 
\subsection{Distributed Computation frameworks}
\label{distcomp}

\subsection{MapReduce and Pregel}

The last few years have witnessed an uptake in distributed data processing research. Among the leading frameworks to exploit distributed computation on commodity hardware is the MapReduce paradigm \cite{mapreduce}. A typical MapReduce program consists of the ``Map'' operator that parcels out work to various nodes within the cluster or map, and the ``Reduce'' phase that applies a reduction operator on the results from each node into a global query. The key contributions of the MapReduce framework are the scalability and fault-tolerance achieved for a variety of applications by optimizing the execution engine, for example, by reassigning tasks when a given execution fails. As with all other parallel and distributed paradigms, the performance of an efficient MapReduce algorithm is contingent upon a reduced communication cost. Of particular challenge is how to efficiently process large graphs. Graph algorithms often exhibit poor locality of reference, and a low compute-to-memory access ratio, which affects the scalability of their parallel adaptations. It is also difficult to maintain a steady degree of parallelism over the course of execution of graph algorithms. Additionally, expressing a graph algorithm in MapReduce requires passing the entire state of the graph from one stage to the next, thus imposing significant communication as well as serialisation in the parallel code. 

The first serious development for supporting graph algorithms using the MapReduce framework is found in Google's Pregel \cite{Pregel}. Instead of coordinating the steps of a chained MapReduce program, Pregel is able to process iteration over supersteps under the Bulk Synchronous Parallel model \cite{Biss04, McColl2, Valiant}. In a BSP algorithm, a computation proceeds in a series of global supersteps. Each superstep consists of three phases:
\begin{enumerate}
\item{A concurrent computation superstep: here, each processor performs local computations using values stored in the local, fast memory of the processor.}
\item{A communication superstep: here, the processes exchange data between themselves if needed for the aggregation of the results computed in (1) above.}
\item{A barrier synchronisation superstep: here, each processor arriving at this point waits until all other processes have reached the same barrier.}
\end{enumerate}
According to this model, a graph algorithm in Pregel is organised as a sequence of iterations, and can be described from the point of view of a vertex, that manages its state and sends messages only to its neighbours. Pregel keeps vertices and edges on the machine that performs computation, and uses network transfers only for messages.

\subsection{Spark and GraphX}

Spark, a distributed computation framework built around the MapReduce paradigm, is a recent Apache foundation software project supported by an execution engine for big data processing. Spark provides for in-memory computation, which refers to the storage of information in the main random access memory (RAM) of dedicated servers rather than in relational databases running on relatively slower disk drives. Using over 80 high-level operators, Spark makes it possible to write code more succinctly, and till this time, is considered one of the fastest frameworks for big data processing. Spark's most notable properties are also thanks to its core, which, in addition for serving as the base engine for large-scale parallel and distributed data processing, is able to handle memory management and fault recovery, scheduling, distributing and monitoring jobs on a cluster, as well as interacting with storage systems.

Spark hinges on parallel abstract data collections called RDDs (resilient distributed datasets), which can distributed across a cluster. These RDDs are immutable, partitioned data structures that can be manipulated through multiple operators like Map, Reduce, and Join. For example, RDDs are created through parallel transformations (e.g., map, group by, filter, join, create from file systems). RDDs can be cached (in-memory) by allowing to keep data sets of interest locally across operations, thus contributing to a substantial speedup. At the same time, Spark uses lineage to support fault tolerance, i.e., record all the operations/transformations that yielded RDDs from a source data. In case of failure, an RDD can be reconstructed given the transformation functions contributing to that RDD. Additionally, after creating RDDs, it is possible to analyse them using actions such as count, reduce, collect and save. Note that all operations/transformations are lazy until one runs an action. At that point, the Spark execution engine pipelines operations and determines an execution plan.

Borrowing from Pregel, GraphX~\cite{graphx} is a platform built on top of Spark that provides APIs for parallel and distributed processing on large graphs. In GraphX, each graph is mapped into different RDDs, where in each RDD one applies the computation on the graph using the “think like a vertex” model. 

