\section{Answers to the comments of Reviewer 2}
%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%


\begin{itemize}
\item The paper has improved by addressing most of the previous comments. However, the presented arguments are not yet convincing as why Spark platform is necessary in the presented analysis. Spark is in the title of the manuscript so this suggests the importance of the role of Spark in the analysis but based on the rest of the paper the use of Spark is not well-motivated and justified. Merely having the capability to use Spark to show that the analysis can be extend is not enough as the presented analysis can be done without Spark in a single computer. I would suggest either tone down the role of Spark or better justify its importance. The importance aspect of this study is the vulnerability analysis and not on what platform it was done, unless one couldn't do this without Spark. As such, the contribution and main focus of the paper needs to be clarified.

~

\answer{
Sure. We do concede that the use of Spark is justified when tackling large graphs that cannot be handled on a serial machine, and that the Message Passing Interface (MPI) is an option to be used in this situation. Despite that our input graph is not dramatically a ``big graph'', our use of Spark is meant to provide for the following: (1) scalability, represented by a solution that is shown to remain promising and effective when the input graph scales to such daunting sizes, when tackling either networks of networks or power plants in larger countries; (2) fault tolerance: if and when the input graph size increases, failures -- aka faults -- resulting from out-of-memory accesses and computations, message loss, network error, to name a few causes, would begin to appear very frequently as opposed to rarely, which, in the absence of a fault-tolerant platform, would require one to re-perform the whole computations. Spark provides for fault-tolerance using lineage techniques as well as efficient distributed in-memory computation. The choice of Spark also renders our system to be suitable for clusters of commodity computers with relatively slow and cheap interconnects, and susceptible to many machine failures. Scalability as well as fault-tolerance have already been discussed in the paper (please see the introduction), but we reckon that we will need to be even more vocal. We have now inserted our explanation above in line of our current response (please see the introduction, third paragraph, in red). We also agree with the reviewer that we should tone down the referencing of Spark especially in the title. For this, please check our new title.}
\end{itemize}



